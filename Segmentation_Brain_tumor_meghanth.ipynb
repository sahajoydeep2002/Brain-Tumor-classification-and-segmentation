{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Segmentation_Brain_tumor_meghanth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meghanth/brain-tumor-classification-and-segmentation/blob/main/Segmentation_Brain_tumor_meghanth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l06laOmNhiaN",
        "outputId": "3ab3ac41-4e70-4285-b5bc-7abeb299839d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 27 06:37:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTdFaUdFEnYZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3VrnUY6x5EO",
        "outputId": "b7251670-7d4a-4c4b-a1f9-fa515f864996"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "BR2gX7xwTit3",
        "outputId": "c69d67a2-927a-4eb0-d2aa-7a0ebed0ec7a"
      },
      "source": [
        "# data containing path to Brain MRI and their corresponding mask\n",
        "brain_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv')\n",
        "brain_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient</th>\n",
              "      <th>RNASeqCluster</th>\n",
              "      <th>MethylationCluster</th>\n",
              "      <th>miRNACluster</th>\n",
              "      <th>CNCluster</th>\n",
              "      <th>RPPACluster</th>\n",
              "      <th>OncosignCluster</th>\n",
              "      <th>COCCluster</th>\n",
              "      <th>histological_type</th>\n",
              "      <th>neoplasm_histologic_grade</th>\n",
              "      <th>tumor_tissue_site</th>\n",
              "      <th>laterality</th>\n",
              "      <th>tumor_location</th>\n",
              "      <th>gender</th>\n",
              "      <th>age_at_initial_pathologic</th>\n",
              "      <th>race</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>death01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA_CS_4941</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA_CS_4942</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA_CS_4943</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA_CS_4944</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA_CS_5393</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Patient  RNASeqCluster  MethylationCluster  ...  race  ethnicity  death01\n",
              "0  TCGA_CS_4941            2.0                 4.0  ...   3.0        2.0      1.0\n",
              "1  TCGA_CS_4942            1.0                 5.0  ...   2.0        NaN      1.0\n",
              "2  TCGA_CS_4943            1.0                 5.0  ...   3.0        NaN      0.0\n",
              "3  TCGA_CS_4944            NaN                 5.0  ...   3.0        NaN      0.0\n",
              "4  TCGA_CS_5393            4.0                 5.0  ...   3.0        NaN      0.0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3NmziIPUCUf",
        "outputId": "cb4d4866-1a83-45c7-b042-272c4a2c10a8"
      },
      "source": [
        "brain_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 110 entries, 0 to 109\n",
            "Data columns (total 18 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Patient                    110 non-null    object \n",
            " 1   RNASeqCluster              92 non-null     float64\n",
            " 2   MethylationCluster         109 non-null    float64\n",
            " 3   miRNACluster               110 non-null    int64  \n",
            " 4   CNCluster                  108 non-null    float64\n",
            " 5   RPPACluster                98 non-null     float64\n",
            " 6   OncosignCluster            105 non-null    float64\n",
            " 7   COCCluster                 110 non-null    int64  \n",
            " 8   histological_type          109 non-null    float64\n",
            " 9   neoplasm_histologic_grade  109 non-null    float64\n",
            " 10  tumor_tissue_site          109 non-null    float64\n",
            " 11  laterality                 109 non-null    float64\n",
            " 12  tumor_location             109 non-null    float64\n",
            " 13  gender                     109 non-null    float64\n",
            " 14  age_at_initial_pathologic  109 non-null    float64\n",
            " 15  race                       108 non-null    float64\n",
            " 16  ethnicity                  102 non-null    float64\n",
            " 17  death01                    109 non-null    float64\n",
            "dtypes: float64(15), int64(2), object(1)\n",
            "memory usage: 15.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcsCqBQXUMdh",
        "outputId": "ac9e6baa-e8ae-4f90-fc96-fd1addc30360"
      },
      "source": [
        "data_map = []\n",
        "for sub_dir_path in glob.glob(\"/content/drive/MyDrive/Colab Notebooks/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n",
        "    try:\n",
        "        dir_name = sub_dir_path.split('/')[-1]\n",
        "        for filename in os.listdir(sub_dir_path):\n",
        "            image_path = sub_dir_path+\"/\"+filename\n",
        "            data_map.extend([dir_name, image_path])\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 20] Not a directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/Segmentation_Brain_Tumor_Data/lgg-mri-segmentation/kaggle_3m/README.md'\n",
            "[Errno 20] Not a directory: '/content/drive/MyDrive/Colab Notebooks/Dataset/Segmentation_Brain_Tumor_Data/lgg-mri-segmentation/kaggle_3m/data.csv'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "cKV5MS_AVOo4",
        "outputId": "33ed375e-0602-4239-81a5-4d83b281bae1"
      },
      "source": [
        "df = pd.DataFrame({\"patient_id\": data_map[::2], \"path\": data_map[1::2]})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              patient_id                                               path\n",
              "0  TCGA_HT_A61B_19991127  /content/drive/MyDrive/Colab Notebooks/Dataset...\n",
              "1  TCGA_HT_A61B_19991127  /content/drive/MyDrive/Colab Notebooks/Dataset...\n",
              "2  TCGA_HT_A61B_19991127  /content/drive/MyDrive/Colab Notebooks/Dataset...\n",
              "3  TCGA_HT_A61B_19991127  /content/drive/MyDrive/Colab Notebooks/Dataset...\n",
              "4  TCGA_HT_A61B_19991127  /content/drive/MyDrive/Colab Notebooks/Dataset..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWDJ0levVg-I",
        "outputId": "c711cba2-005c-4947-a0d6-0188ddfeaef6"
      },
      "source": [
        "df_imgs = df[~df['path'].str.contains(\"mask\")]\n",
        "df_masks = df[df['path'].str.contains(\"mask\")]\n",
        "\n",
        "BASE_LEN = 152\n",
        "END_IMG_LEN = 4\n",
        "END_MASK_LEN = 9\n",
        "\n",
        "\n",
        "imgs = sorted(df_imgs[\"path\"].values, key=lambda x: int(x[BASE_LEN:-END_IMG_LEN]))\n",
        "masks = sorted(df_masks[\"path\"].values, key=lambda x: int(x[BASE_LEN:-END_MASK_LEN]))\n",
        "\n",
        "\n",
        "# Sorting check\n",
        "idx = random.randint(0, len(imgs)-1)\n",
        "print(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path to the Image: /content/drive/MyDrive/Colab Notebooks/Dataset/Segmentation_Brain_Tumor_Data/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_23.tif \n",
            "Path to the Mask: /content/drive/MyDrive/Colab Notebooks/Dataset/Segmentation_Brain_Tumor_Data/lgg-mri-segmentation/kaggle_3m/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_23_mask.tif\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHbn4-YwZF1X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "445a25d6-2227-4f50-821a-3e6af22dfcff"
      },
      "source": [
        "# Final dataframe\n",
        "brain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n",
        "                         \"image_path\": imgs,\n",
        "                         \"mask_path\": masks\n",
        "                        })\n",
        "\n",
        "def pos_neg_diagnosis(mask_path):\n",
        "    value = np.max(cv2.imread(mask_path))\n",
        "    if value > 0 : \n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "brain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))\n",
        "brain_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>mask_path</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA_HT_A61B_19991127</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>/content/drive/MyDrive/Colab Notebooks/Dataset...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              patient_id  ... mask\n",
              "0  TCGA_HT_A61B_19991127  ...    0\n",
              "1  TCGA_HT_A61B_19991127  ...    0\n",
              "2  TCGA_HT_A61B_19991127  ...    0\n",
              "3  TCGA_HT_A61B_19991127  ...    0\n",
              "4  TCGA_HT_A61B_19991127  ...    0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Dbc3vgZYrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1872f701-41a5-4af0-859c-bd8edbd27e95"
      },
      "source": [
        "brain_df_mask = brain_df[brain_df['mask']==1]\n",
        "brain_df_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1373, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGYFopEZdVy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a619460-0344-42fc-8f2e-9f00e17427b1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# creating test, train and val sets\n",
        "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
        "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
        "print(\"Train size is \", len(X_train), \"valid size is \", len(X_val),\"test size is\",len(X_test))\n",
        "\n",
        "train_ids = list(X_train.image_path)\n",
        "train_mask = list(X_train.mask_path)\n",
        "\n",
        "val_ids = list(X_val.image_path)\n",
        "val_mask= list(X_val.mask_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size is  1167 valid size is  103 test size is 103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfo2Jp-jfcSJ"
      },
      "source": [
        "image_size = 256\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YOxS3ejdg7A"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from tensorflow.keras import backend as K \n",
        "\n",
        "#creating a custom datagenerator\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, ids , mask, image_dir = ' ', batch_size = 32, img_h = 256, img_w = 256, shuffle = True):\n",
        "\n",
        "        self.ids = ids\n",
        "        self.mask = mask\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.img_h = img_h\n",
        "        self.img_w = img_w\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Get the number of batches per epoch'\n",
        "\n",
        "        return int(np.floor(len(self.ids))/self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate a batch of data'\n",
        "\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        list_ids = [self.ids[i] for i in indexes]\n",
        "\n",
        "        list_mask = [self.mask[i] for i in indexes]\n",
        "\n",
        "        X, y = self.__data_generation(list_ids, list_mask)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Used fror updating the indices after each epoch, once at the beginning as well as at the end of each epoch'\n",
        "        self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_ids, list_mask):\n",
        "        'generate the data corresponding the indexex in a given batch of images'\n",
        "\n",
        "        X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "        y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
        "\n",
        "        for i in range(len(list_ids)):\n",
        "            img_path = str(list_ids[i])\n",
        "            mask_path = str(list_mask[i])\n",
        "\n",
        "            img = io.imread(img_path)\n",
        "            mask = io.imread(mask_path)\n",
        "\n",
        "            img = cv2.resize(img, (self.img_h, self.img_w))\n",
        "            img = np.array(img, dtype=np.float64)\n",
        "            mask = cv2.resize(mask, (self.img_h, self.img_w))\n",
        "            mask = np.array(mask, dtype=np.float64)\n",
        "\n",
        "            img -= img.mean()\n",
        "            img /= img.std()\n",
        "\n",
        "            mask -= mask.mean()\n",
        "            mask /= mask.std()\n",
        "\n",
        "            X[i,] = img\n",
        "            y[i,] = np.expand_dims(mask, axis = 2)\n",
        "\n",
        "        y = (y>0).astype(int)\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74EOpBvaC6sZ"
      },
      "source": [
        "train_data = DataGenerator(train_ids, train_mask)\n",
        "val_data = DataGenerator(val_ids, val_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP9Ewg3KckVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7671699-abd4-4e93-8a8a-d2ab814d39e8"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljVlSM3tfH9Q"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBJXSJdlem4o"
      },
      "source": [
        "def bn_act(x, act=True):\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = keras.layers.Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    conv = keras.layers.Dropout(0.3)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    \n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = keras.layers.Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "    \n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = keras.layers.Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = keras.layers.UpSampling2D((2, 2))(x)\n",
        "    c = keras.layers.Concatenate()([u, xskip])\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPzfB4Rsetox"
      },
      "source": [
        "def ResUNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((image_size, image_size, 3))\n",
        "    \n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "    \n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "    \n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "    \n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "    \n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "    \n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "    \n",
        "    outputs = keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hsoXLbLDJFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76fee74-0d20-43d6-a650-6d5d4cd307fe"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNrbtYgvHuum"
      },
      "source": [
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "epsilon = 1e-5\n",
        "smooth = 1\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    \n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred)) / (K.sum(y_true) + K.sum(y_pred))\n",
        "\n",
        "def IoU(pred, targs):\n",
        "    pred = (pred>0).float()\n",
        "    intersection = (pred*targs).sum()\n",
        "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vifz6sTicSv"
      },
      "source": [
        "model = ResUNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsyGClZ8IWR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1947344d-9a74-4119-8801-f7bc87b0cd89"
      },
      "source": [
        "\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model.compile(optimizer = adam, \n",
        "                  loss = focal_tversky, \n",
        "                  metrics = [tversky, dice_coef]\n",
        "                 )\n",
        "#callbacks\n",
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min', \n",
        "                              verbose=1, \n",
        "                              patience=20\n",
        "                             )\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"ResUNet-segModel-weights.hdf5\", \n",
        "                               verbose=1, \n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HecnLuoYfowf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05c465c-1fb9-42fe-9498-26f2577122e5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 16) 64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256, 256, 16) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256, 256, 16) 0           dropout[0][0]                    \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128, 128, 32) 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 32) 544         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 128, 128, 32) 0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128, 128, 32) 0           batch_normalization_4[0][0]      \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 32) 128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   18496       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64, 64, 64)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   2112        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 64, 64, 64)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  73856       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 128)  0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  8320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 128)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 128)  0           batch_normalization_10[0][0]     \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 256)  295168      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 256)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  33024       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 16, 16, 256)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 16, 16, 256)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 16, 16, 256)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 32, 32, 256)  0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 384)  0           up_sampling2d[0][0]              \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 384)  1536        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 384)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 256)  884992      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 256)  0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 256)  1024        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 256)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 256)  98560       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 256)  590080      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 256)  1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 256)  0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 256)  0           batch_normalization_18[0][0]     \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 320)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 64, 64, 320)  1280        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 320)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 128)  368768      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 64, 64, 128)  0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 128)  512         dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 128)  41088       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 64, 64, 128)  0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 64, 64, 128)  0           batch_normalization_21[0][0]     \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 160 0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 128, 128, 160 640         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 128, 160 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 128, 128, 64) 92224       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 128, 128, 64) 0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 128, 128, 64) 256         dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 128, 128, 64) 10304       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 128, 64) 36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 128, 128, 64) 0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n",
            "                                                                 dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 80) 0           up_sampling2d_3[0][0]            \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 256, 256, 80) 320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 256, 256, 80) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 256, 256, 32) 23072       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 256, 256, 32) 0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 256, 256, 32) 128         dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 256, 32) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 256, 256, 32) 2592        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 256, 256, 32) 9248        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 256, 256, 32) 128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 256, 256, 32) 0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 256, 256, 32) 0           batch_normalization_27[0][0]     \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 256, 256, 1)  33          add_8[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,723,057\n",
            "Trainable params: 4,715,761\n",
            "Non-trainable params: 7,296\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gRXzPSPIjug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1e5dc3-076f-4d20-9e56-ec3eb0ec3ead"
      },
      "source": [
        "hist = model.fit(train_data, \n",
        "                  epochs = 100, \n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr]\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 491s 12s/step - loss: 0.8376 - tversky: 0.2095 - dice_coef: 0.1412 - val_loss: 0.8214 - val_tversky: 0.2308 - val_dice_coef: 0.1535\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.82137, saving model to ResUNet-segModel-weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "36/36 [==============================] - 33s 906ms/step - loss: 0.5564 - tversky: 0.5404 - dice_coef: 0.4834 - val_loss: 0.6340 - val_tversky: 0.4540 - val_dice_coef: 0.3504\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.82137 to 0.63405, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 31s 862ms/step - loss: 0.4855 - tversky: 0.6177 - dice_coef: 0.5750 - val_loss: 0.5528 - val_tversky: 0.5459 - val_dice_coef: 0.5341\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.63405 to 0.55279, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 32s 872ms/step - loss: 0.4403 - tversky: 0.6636 - dice_coef: 0.6307 - val_loss: 0.3826 - val_tversky: 0.7219 - val_dice_coef: 0.6932\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.55279 to 0.38257, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 31s 864ms/step - loss: 0.3881 - tversky: 0.7160 - dice_coef: 0.6933 - val_loss: 0.4138 - val_tversky: 0.6909 - val_dice_coef: 0.6023\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.38257\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 32s 870ms/step - loss: 0.3675 - tversky: 0.7357 - dice_coef: 0.7092 - val_loss: 0.6200 - val_tversky: 0.4710 - val_dice_coef: 0.3527\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.38257\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 32s 877ms/step - loss: 0.3436 - tversky: 0.7583 - dice_coef: 0.7311 - val_loss: 0.4574 - val_tversky: 0.6449 - val_dice_coef: 0.5363\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.38257\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 32s 882ms/step - loss: 0.3189 - tversky: 0.7815 - dice_coef: 0.7582 - val_loss: 0.3941 - val_tversky: 0.7100 - val_dice_coef: 0.6599\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.38257\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.3111 - tversky: 0.7884 - dice_coef: 0.7629 - val_loss: 0.4640 - val_tversky: 0.6396 - val_dice_coef: 0.5307\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.38257\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.2875 - tversky: 0.8097 - dice_coef: 0.7837 - val_loss: 0.3346 - val_tversky: 0.7672 - val_dice_coef: 0.7265\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.38257 to 0.33458, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.2970 - tversky: 0.8010 - dice_coef: 0.7787 - val_loss: 0.3454 - val_tversky: 0.7576 - val_dice_coef: 0.6805\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.33458\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2777 - tversky: 0.8180 - dice_coef: 0.7927 - val_loss: 0.4069 - val_tversky: 0.6968 - val_dice_coef: 0.6036\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.33458\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2743 - tversky: 0.8210 - dice_coef: 0.7972 - val_loss: 0.3201 - val_tversky: 0.7810 - val_dice_coef: 0.7453\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.33458 to 0.32006, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.2636 - tversky: 0.8303 - dice_coef: 0.8066 - val_loss: 0.7354 - val_tversky: 0.3360 - val_dice_coef: 0.2388\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.32006\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2527 - tversky: 0.8395 - dice_coef: 0.8145 - val_loss: 0.3075 - val_tversky: 0.7913 - val_dice_coef: 0.7305\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.32006 to 0.30746, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.2493 - tversky: 0.8424 - dice_coef: 0.8221 - val_loss: 0.2989 - val_tversky: 0.7996 - val_dice_coef: 0.7419\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.30746 to 0.29889, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.2379 - tversky: 0.8520 - dice_coef: 0.8284 - val_loss: 0.2727 - val_tversky: 0.8232 - val_dice_coef: 0.8088\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.29889 to 0.27268, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.2330 - tversky: 0.8562 - dice_coef: 0.8329 - val_loss: 0.2694 - val_tversky: 0.8256 - val_dice_coef: 0.7789\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.27268 to 0.26944, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 32s 892ms/step - loss: 0.2319 - tversky: 0.8570 - dice_coef: 0.8346 - val_loss: 0.2899 - val_tversky: 0.8076 - val_dice_coef: 0.7469\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.26944\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 32s 883ms/step - loss: 0.2227 - tversky: 0.8646 - dice_coef: 0.8411 - val_loss: 0.4549 - val_tversky: 0.6501 - val_dice_coef: 0.5368\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.26944\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2226 - tversky: 0.8647 - dice_coef: 0.8416 - val_loss: 0.2710 - val_tversky: 0.8246 - val_dice_coef: 0.7871\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.26944\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2122 - tversky: 0.8729 - dice_coef: 0.8498 - val_loss: 0.2312 - val_tversky: 0.8579 - val_dice_coef: 0.8196\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.26944 to 0.23123, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.2115 - tversky: 0.8736 - dice_coef: 0.8499 - val_loss: 0.3109 - val_tversky: 0.7892 - val_dice_coef: 0.7212\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.23123\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 32s 894ms/step - loss: 0.2083 - tversky: 0.8762 - dice_coef: 0.8542 - val_loss: 0.2462 - val_tversky: 0.8441 - val_dice_coef: 0.7963\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.23123\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1950 - tversky: 0.8865 - dice_coef: 0.8645 - val_loss: 0.2928 - val_tversky: 0.8052 - val_dice_coef: 0.7361\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.23123\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.2038 - tversky: 0.8796 - dice_coef: 0.8552 - val_loss: 0.2419 - val_tversky: 0.8492 - val_dice_coef: 0.7960\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.23123\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 32s 883ms/step - loss: 0.1869 - tversky: 0.8929 - dice_coef: 0.8701 - val_loss: 0.2351 - val_tversky: 0.8547 - val_dice_coef: 0.7965\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.23123\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1991 - tversky: 0.8835 - dice_coef: 0.8594 - val_loss: 0.2814 - val_tversky: 0.8155 - val_dice_coef: 0.7477\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.23123\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 32s 883ms/step - loss: 0.1878 - tversky: 0.8921 - dice_coef: 0.8690 - val_loss: 0.2568 - val_tversky: 0.8366 - val_dice_coef: 0.7753\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.23123\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1845 - tversky: 0.8947 - dice_coef: 0.8719 - val_loss: 0.1922 - val_tversky: 0.8885 - val_dice_coef: 0.8611\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.23123 to 0.19219, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1806 - tversky: 0.8976 - dice_coef: 0.8758 - val_loss: 0.2141 - val_tversky: 0.8714 - val_dice_coef: 0.8346\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.19219\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1853 - tversky: 0.8941 - dice_coef: 0.8737 - val_loss: 0.2746 - val_tversky: 0.8211 - val_dice_coef: 0.7427\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.19219\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1773 - tversky: 0.9002 - dice_coef: 0.8767 - val_loss: 0.1811 - val_tversky: 0.8972 - val_dice_coef: 0.8700\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.19219 to 0.18109, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1740 - tversky: 0.9026 - dice_coef: 0.8812 - val_loss: 0.2123 - val_tversky: 0.8729 - val_dice_coef: 0.8296\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.18109\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1719 - tversky: 0.9042 - dice_coef: 0.8830 - val_loss: 0.1893 - val_tversky: 0.8911 - val_dice_coef: 0.8674\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.18109\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1716 - tversky: 0.9044 - dice_coef: 0.8836 - val_loss: 0.2556 - val_tversky: 0.8375 - val_dice_coef: 0.7721\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.18109\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1673 - tversky: 0.9076 - dice_coef: 0.8869 - val_loss: 0.2563 - val_tversky: 0.8371 - val_dice_coef: 0.7708\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.18109\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1640 - tversky: 0.9100 - dice_coef: 0.8893 - val_loss: 0.2274 - val_tversky: 0.8609 - val_dice_coef: 0.8041\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.18109\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1608 - tversky: 0.9124 - dice_coef: 0.8924 - val_loss: 0.2033 - val_tversky: 0.8803 - val_dice_coef: 0.8367\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.18109\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 32s 882ms/step - loss: 0.1609 - tversky: 0.9122 - dice_coef: 0.8923 - val_loss: 0.1924 - val_tversky: 0.8881 - val_dice_coef: 0.8534\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.18109\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1646 - tversky: 0.9095 - dice_coef: 0.8887 - val_loss: 0.1971 - val_tversky: 0.8853 - val_dice_coef: 0.8471\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.18109\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1621 - tversky: 0.9114 - dice_coef: 0.8907 - val_loss: 0.2728 - val_tversky: 0.8231 - val_dice_coef: 0.7463\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.18109\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1588 - tversky: 0.9138 - dice_coef: 0.8940 - val_loss: 0.1923 - val_tversky: 0.8882 - val_dice_coef: 0.8545\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.18109\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1529 - tversky: 0.9180 - dice_coef: 0.8991 - val_loss: 0.1922 - val_tversky: 0.8891 - val_dice_coef: 0.8500\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.18109\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1511 - tversky: 0.9193 - dice_coef: 0.9012 - val_loss: 0.1829 - val_tversky: 0.8958 - val_dice_coef: 0.8574\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.18109\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1507 - tversky: 0.9196 - dice_coef: 0.9004 - val_loss: 0.1971 - val_tversky: 0.8850 - val_dice_coef: 0.8396\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.18109\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1490 - tversky: 0.9208 - dice_coef: 0.9013 - val_loss: 0.1914 - val_tversky: 0.8894 - val_dice_coef: 0.8508\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.18109\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 32s 892ms/step - loss: 0.1475 - tversky: 0.9219 - dice_coef: 0.9033 - val_loss: 0.1943 - val_tversky: 0.8869 - val_dice_coef: 0.8472\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.18109\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1487 - tversky: 0.9210 - dice_coef: 0.9022 - val_loss: 0.1797 - val_tversky: 0.8985 - val_dice_coef: 0.8639\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.18109 to 0.17966, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1480 - tversky: 0.9215 - dice_coef: 0.9029 - val_loss: 0.1978 - val_tversky: 0.8847 - val_dice_coef: 0.8412\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.17966\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1480 - tversky: 0.9216 - dice_coef: 0.9024 - val_loss: 0.1833 - val_tversky: 0.8958 - val_dice_coef: 0.8568\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.17966\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 32s 883ms/step - loss: 0.1471 - tversky: 0.9221 - dice_coef: 0.9037 - val_loss: 0.1866 - val_tversky: 0.8931 - val_dice_coef: 0.8574\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.17966\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1463 - tversky: 0.9228 - dice_coef: 0.9043 - val_loss: 0.1817 - val_tversky: 0.8966 - val_dice_coef: 0.8630\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.17966\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1470 - tversky: 0.9222 - dice_coef: 0.9039 - val_loss: 0.1809 - val_tversky: 0.8975 - val_dice_coef: 0.8639\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.17966\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 32s 892ms/step - loss: 0.1451 - tversky: 0.9235 - dice_coef: 0.9055 - val_loss: 0.1840 - val_tversky: 0.8949 - val_dice_coef: 0.8596\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.17966\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1458 - tversky: 0.9230 - dice_coef: 0.9040 - val_loss: 0.1870 - val_tversky: 0.8930 - val_dice_coef: 0.8553\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.17966\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1448 - tversky: 0.9238 - dice_coef: 0.9058 - val_loss: 0.1948 - val_tversky: 0.8869 - val_dice_coef: 0.8434\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.17966\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1456 - tversky: 0.9230 - dice_coef: 0.9039 - val_loss: 0.1810 - val_tversky: 0.8974 - val_dice_coef: 0.8635\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.17966\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1469 - tversky: 0.9223 - dice_coef: 0.9044 - val_loss: 0.1951 - val_tversky: 0.8863 - val_dice_coef: 0.8404\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.17966\n",
            "\n",
            "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 32s 882ms/step - loss: 0.1439 - tversky: 0.9244 - dice_coef: 0.9053 - val_loss: 0.1882 - val_tversky: 0.8921 - val_dice_coef: 0.8532\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.17966\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1446 - tversky: 0.9238 - dice_coef: 0.9065 - val_loss: 0.1904 - val_tversky: 0.8903 - val_dice_coef: 0.8513\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.17966\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1425 - tversky: 0.9255 - dice_coef: 0.9065 - val_loss: 0.1933 - val_tversky: 0.8878 - val_dice_coef: 0.8459\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.17966\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1437 - tversky: 0.9246 - dice_coef: 0.9060 - val_loss: 0.1925 - val_tversky: 0.8884 - val_dice_coef: 0.8483\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.17966\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1423 - tversky: 0.9256 - dice_coef: 0.9085 - val_loss: 0.1860 - val_tversky: 0.8936 - val_dice_coef: 0.8563\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.17966\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1424 - tversky: 0.9255 - dice_coef: 0.9072 - val_loss: 0.1896 - val_tversky: 0.8909 - val_dice_coef: 0.8534\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.17966\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1422 - tversky: 0.9257 - dice_coef: 0.9081 - val_loss: 0.1807 - val_tversky: 0.8978 - val_dice_coef: 0.8603\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.17966\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1421 - tversky: 0.9256 - dice_coef: 0.9075 - val_loss: 0.1784 - val_tversky: 0.8994 - val_dice_coef: 0.8619\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.17966 to 0.17842, saving model to ResUNet-segModel-weights.hdf5\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1426 - tversky: 0.9253 - dice_coef: 0.9066 - val_loss: 0.1910 - val_tversky: 0.8900 - val_dice_coef: 0.8510\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.17842\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1419 - tversky: 0.9259 - dice_coef: 0.9084 - val_loss: 0.1849 - val_tversky: 0.8943 - val_dice_coef: 0.8556\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.17842\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1426 - tversky: 0.9252 - dice_coef: 0.9072 - val_loss: 0.1887 - val_tversky: 0.8918 - val_dice_coef: 0.8517\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.17842\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1428 - tversky: 0.9252 - dice_coef: 0.9068 - val_loss: 0.1842 - val_tversky: 0.8952 - val_dice_coef: 0.8549\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.17842\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1433 - tversky: 0.9248 - dice_coef: 0.9065 - val_loss: 0.1845 - val_tversky: 0.8948 - val_dice_coef: 0.8555\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.17842\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1418 - tversky: 0.9259 - dice_coef: 0.9070 - val_loss: 0.1905 - val_tversky: 0.8902 - val_dice_coef: 0.8523\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.17842\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 32s 893ms/step - loss: 0.1424 - tversky: 0.9255 - dice_coef: 0.9083 - val_loss: 0.1892 - val_tversky: 0.8913 - val_dice_coef: 0.8508\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.17842\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1436 - tversky: 0.9247 - dice_coef: 0.9060 - val_loss: 0.1837 - val_tversky: 0.8956 - val_dice_coef: 0.8576\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.17842\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1424 - tversky: 0.9254 - dice_coef: 0.9058 - val_loss: 0.1839 - val_tversky: 0.8949 - val_dice_coef: 0.8597\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.17842\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1425 - tversky: 0.9254 - dice_coef: 0.9070 - val_loss: 0.1847 - val_tversky: 0.8946 - val_dice_coef: 0.8576\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.17842\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1415 - tversky: 0.9261 - dice_coef: 0.9083 - val_loss: 0.1873 - val_tversky: 0.8927 - val_dice_coef: 0.8528\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.17842\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 32s 883ms/step - loss: 0.1413 - tversky: 0.9263 - dice_coef: 0.9081 - val_loss: 0.1876 - val_tversky: 0.8923 - val_dice_coef: 0.8541\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.17842\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 32s 885ms/step - loss: 0.1408 - tversky: 0.9266 - dice_coef: 0.9087 - val_loss: 0.1842 - val_tversky: 0.8951 - val_dice_coef: 0.8555\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.17842\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 32s 894ms/step - loss: 0.1421 - tversky: 0.9257 - dice_coef: 0.9078 - val_loss: 0.1791 - val_tversky: 0.8989 - val_dice_coef: 0.8616\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.17842\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 32s 889ms/step - loss: 0.1420 - tversky: 0.9258 - dice_coef: 0.9077 - val_loss: 0.1846 - val_tversky: 0.8949 - val_dice_coef: 0.8552\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.17842\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1411 - tversky: 0.9263 - dice_coef: 0.9085 - val_loss: 0.1825 - val_tversky: 0.8964 - val_dice_coef: 0.8595\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.17842\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 32s 887ms/step - loss: 0.1418 - tversky: 0.9259 - dice_coef: 0.9076 - val_loss: 0.1870 - val_tversky: 0.8928 - val_dice_coef: 0.8551\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.17842\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 32s 884ms/step - loss: 0.1413 - tversky: 0.9262 - dice_coef: 0.9080 - val_loss: 0.1890 - val_tversky: 0.8913 - val_dice_coef: 0.8526\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.17842\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 32s 886ms/step - loss: 0.1416 - tversky: 0.9260 - dice_coef: 0.9082 - val_loss: 0.1887 - val_tversky: 0.8916 - val_dice_coef: 0.8526\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.17842\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 32s 888ms/step - loss: 0.1427 - tversky: 0.9253 - dice_coef: 0.9068 - val_loss: 0.1839 - val_tversky: 0.8950 - val_dice_coef: 0.8578\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.17842\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
            "Epoch 00087: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxvdoCySI2Ij"
      },
      "source": [
        "model_json = model_seg.to_json()\n",
        "with open(\"ResUNet-model.json\",\"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1kZrM_aKL2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cbada3-31cb-4bf1-9428-1e5346fe99c6"
      },
      "source": [
        "test_ids = list(X_test.image_path)\n",
        "test_mask = list(X_test.mask_path)\n",
        "test_data = DataGenerator(test_ids, test_mask)\n",
        "_, tv, dc = model.evaluate(test_data)\n",
        "print(\"Segmentation tversky is {:.2f}%\".format(tv*100))\n",
        "print(\"Segmentation tversky is {:.2f}%\".format(dc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 28s 14s/step - loss: 0.1696 - tversky: 0.9059 - dice_coef: 0.8658\n",
            "Segmentation tversky is 90.59%\n",
            "Segmentation tversky is 86.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPVELFieSPNU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UG6CXH-KP7G"
      },
      "source": [
        "# plt.figure(figsize=(12,5))\n",
        "# plt.subplot(1,2,1)\n",
        "plt.plot(hist.history['loss']);\n",
        "plt.plot(hist.history['val_loss']);\n",
        "plt.title(\"SEG Model focal tversky Loss\");\n",
        "plt.ylabel(\"focal tversky loss\");\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.legend(['train', 'val']);\n",
        "\n",
        "# plt.subplot(1,2,2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zarjXMXqM3AY"
      },
      "source": [
        "plt.plot(hist.history['tversky']);\n",
        "plt.plot(hist.history['val_tversky']);\n",
        "plt.title(\"SEG Model tversky score\");\n",
        "plt.ylabel(\"tversky Accuracy\");\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.legend(['train', 'val']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "a1n6JNhs7h00",
        "outputId": "7e0579c6-d3c8-496f-9b54-a397b291838b"
      },
      "source": [
        "plt.plot(hist.history['dice_coef']);\n",
        "plt.plot(hist.history['val_dice_coef']);\n",
        "plt.title(\"SEG Model dice_coef score\");\n",
        "plt.ylabel(\"dice_coef Accuracy\");\n",
        "plt.xlabel(\"Epochs\");\n",
        "plt.legend(['train', 'val']);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpg3QnFuKuf7"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model_seg.save('Segmentation.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzWczs3ohSA1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}